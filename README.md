# Zindi-arm-unicef-disaster-vulnerability-challenge

### Competition hosted on [Zindi](https://zindi.africa/competitions/arm-unicef-disaster-vulnerability-challenge)
### Overview
The people of Malawi have experienced an array of natural disasters and climatic shocks in recent years, including droughts, floods and landslides. The economic impacts of these disasters, coupled with Covid-19 and other global issues, negatively affect the health and wellbeing of most Malawians. People living in rural areas (more than 80% of Malawians) have been hit hardest.

There have been great strides in mapping flood extents and corresponding damages caused by these floods around the world, using satellite imagery. However, there are still gaps in determining the real number of affected populations, especially in rural areas in Malawi. Many houses in rural areas are often constructed with traditional grass-thatched roofs, and these are missed by the algorithms using satellite or aerial imagery to count populations or identify buildings affected by floods.

The objective of this competition is to create a machine-learning algorithm that counts the number of grass-thatch, tin and other roofed houses in aerial (drone) imagery. Ensuring more accurate estimates of affected populations in the case of a disaster allows these communities to be evacuated or for aid to be provided more effectively, helping to improve response times and save lives in rural Malawi.

### Data Overview
There are 4772 images in the train and 2 045 images in the test.

Each category of dwelling is assigned a number: 1 is Other, 2 is Tin and 3 is Thatch.

#### Evaluation metric is Mean Absolute Error.

### My Approach
### Exploratory Data Analysis
  * Target analysis
    * Unique images per target class
    * Number of annotations per target class
  * Visualize a sample image with annotation by target class
  * Bounding box aspect ratio analysis
  * Overlapping bounding boxes analysis
  * Bounding box area analysis
  * Basic image-level information analysis
    * Entropy
    * Contrast
    * Blur
  * Image duplication analysis
    * Find duplication images using the EfficientNet model.
      
The notebook for exploratory data analysis is available on Kaggle.[![Open in Kaggle](https://img.shields.io/static/v1?label=&message=Open%20in%20Kaggle&labelColor=grey&color=blue&logo=kaggle)](https://www.kaggle.com/code/hari141v/arm-unicef-disaster-vulnerability-challenge-eda)

### Model

### Data Preparation
 * Removed annotation with zero height
 * Removed narrow bounding box
 * Removed null bounding box rows
 * Select unique images and split them into 5-fold
 * Data Augmentation
   * Images are manually augmented 10 times
   * Image augmentations
     * RandomRotate90
     * HorizontalFlip
     * VerticalFlip
     * SafeRotate
     * Transpose
     * HueSaturationValue
     * Blur
     * MedianBlur
     * RandomBrightnessContrast
### Model
 * Trained the yolov8n model on the first fold of the five-fold training data with the listed augmentations. 100 epochs were used.
 * Model parameters
   * optimizer: SGD
   * batch: 32
   * Image size: 640
   * patience: 10
   * cos_lr: True
   * augment: True
 * The test data was predicted with 0.6 confidence
 * Tracked the model's performance using [WANDB](https://wandb.ai/hari141v/arm-unicef-disaster-vulnerability-challenge/runs/c35k2vlb?nw=nwuserhari141v)
 * The model was trained on the Kaggle platform with a GPU (Tesla P100-PCIE-16GB)

# Final Competiton Rank: 138/347 | Score: 0.328987194
